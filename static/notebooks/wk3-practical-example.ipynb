---

## Putting It All Together: A Code Example

Let's apply what we've learned by training a simple **Linear Regression** model using Python's Scikit-learn library. Our goal is to predict a value based on a single input feature.

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs>
<TabItem value="py" label="Python Code" default>

```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# 1. Create some sample data
# Let's pretend we have data where y is roughly 2*x + 3 + some noise
X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])
y = np.array([5.1, 6.9, 9.2, 11, 13.3, 15.2, 17.1, 18.9, 21.3, 23])

# 2. Split data into training and testing sets
# We use the test set to get an unbiased evaluation of our final model.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 3. Initialize the Model
# This creates an instance of the Linear Regression model.
model = LinearRegression()

# 4. Train the Model
# The .fit() method is where the training loop (gradient descent, etc.) happens.
# Scikit-learn does all the hard work for us!
model.fit(X_train, y_train)

# 5. Make Predictions
# Use the trained model to predict on the unseen test data.
y_pred = model.predict(X_test)

# 6. Evaluate the Model
# We use the metrics we learned about earlier.
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print the results
print(f"Model's learned slope (weight): {model.coef_[0]:.2f}")
print(f"Model's learned intercept (bias): {model.intercept_:.2f}")
print(f"--- Evaluation on Test Set ---")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (RÂ²) Score: {r2:.2f}")